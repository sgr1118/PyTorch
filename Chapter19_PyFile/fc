{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPCmzzQeq58IcKyfQKAtAcp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"upvHhZg2CBIk"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","\n","class Block(nn.Module):\n","    \n","    def __init__(self,\n","                 input_size,\n","                 output_size,\n","                 use_batch_norm=True,\n","                 dropout_p=.4):\n","        self.input_size = input_size\n","        self.output_size = output_size\n","        self.use_batch_norm = use_batch_norm\n","        self.dropout_p = dropout_p\n","        \n","        super().__init__()\n","        \n","        def get_regularizer(use_batch_norm, size): # 정규화 수행\n","            return nn.BatchNorm1d(size) if use_batch_norm else nn.Dropout(dropout_p) # 드롭아웃\n","        \n","        self.block = nn.Sequential(\n","            nn.Linear(input_size, output_size),\n","            nn.LeakyReLU(),\n","            get_regularizer(use_batch_norm, output_size),\n","        )\n","        \n","    def forward(self, x):\n","        # |x| = (batch_size, input_size)\n","        y = self.block(x)\n","        # |y| = (batch_size, output_size)\n","        \n","        return y\n","\n","    \n","class ImageClassifier(nn.Module):\n","\n","    def __init__(self,\n","                 input_size,\n","                 output_size,\n","                 hidden_sizes=[500, 400, 300, 200, 100],\n","                 use_batch_norm=True,\n","                 dropout_p=.3):\n","        \n","        super().__init__()\n","\n","        assert len(hidden_sizes) > 0, 'hidden layers를 구체화해야 한다.'\n","\n","        last_hidden_size = input_size\n","        blocks = []\n","        for hidden_size in hidden_sizes:\n","            blocks += [Block(\n","                last_hidden_size,\n","                hidden_size,\n","                use_batch_norm,\n","                dropout_p\n","            )]\n","            last_hidden_size = hidden_size\n","        \n","        self.layers = nn.Sequential(\n","            *blocks,\n","            nn.Linear(last_hidden_size, output_size),\n","            nn.LogSoftmax(dim=-1),\n","        )\n","        \n","    def forward(self, x):\n","        # |x| = (batch_size, input_size)        \n","        y = self.layers(x)\n","        # |y| = (batch_size, output_size)\n","        \n","        return y"]}]}