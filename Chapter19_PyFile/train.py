# -*- coding: utf-8 -*-
"""train

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/152GpRA3tBP6GLLkR2UeM2Wv-iJt1s86Q
"""

import argparse

import torch
import torch.nn as nn
import torch.optim as optim

from mnist_classifier.trainer import Trainer

from mnist_classifier.utils import load_mnist
from mnist_classifier.utils import split_data
from mnist_classifier.utils import get_model

# define_argparser를 통하여 입력한 파라미터들을 config라는 객체에 저장한다.

# def define_argparser():
#     p = argparse.ArgumentParser()

#     # 모델 가중치가 저장될 경로
#     p.add_argument('--model_fn', required=True) # required=True 실행 시 파라미터가 필수적으로 입력이 되어야 한다.
#     # 학습이 수행될 크래픽카드 인덱스 번호 (0부터 시작, 0 또는 그래픽카드 없는 경우 -1)
#     p.add_argument('--gpu_id', type = int, default=0 if torch.cuda.is_available() else -1)
#     # 학습데이터 내에서 검증 데이터가 차지하는 비율
#     p.add_argument('--train_ratio', type = float, default = .8)
#     # 미니배치 크기
#     p.add_argument('--batch_size', type = int, default = 256)
#     # 에포크 개수
#     p.add_argument('--n_epochs', type = int, default = 20)

#     # 모델의 계층 개수
#     p.add_argument('--n_layers', type = int, default = 5)
#     # 드롭아웃 사용 여부
#     p.add_argument('--use_dropout', action = 'store_true')
#     # 드롭아웃 사용 시 드롭 확률
#     p.add_argument('--dropout_p', type = float, default = .3)
#     # 학습 시 로그 출력의 정도
#     p.add_argument('--verbose', type = int, default = 1)

#     config = p.parse_args()

#     return config

def define_argparser():
    p = argparse.ArgumentParser()

    p.add_argument('--model_fn', required=True)
    p.add_argument('--gpu_id', type=int, default=0 if torch.cuda.is_available() else -1)

    p.add_argument('--train_ratio', type=float, default=.8)

    p.add_argument('--batch_size', type=int, default=256)
    p.add_argument('--n_epochs', type=int, default=20)

    p.add_argument("--model", default="fc", choices=["fc", "cnn", "rnn"])

    p.add_argument('--n_layers', type=int, default=5)
    p.add_argument('--use_dropout', action='store_true')
    p.add_argument('--dropout_p', type=float, default=.3)
    p.add_argument('--hidden_size', type=int, default=128)

    p.add_argument('--verbose', type=int, default=1)

    config = p.parse_args()

    return config

def main(config):
    # 시용자 정의 구성에 따라 장치를 설정.
    device = torch.device('cpu') if config.gpu_id < 0 else torch.device('cuda:%d' % config.gpu_id)

    # 데이터를 불러와 학습/검증용으로 나누기
    x, y = load_mnist(is_train=True, flatten=(config.model == "fc"))
    x, y = split_data(x.to(device), y.to(device), train_ratio=config.train_ratio)

    print("Train:", x[0].shape, y[0].shape)
    print("Valid:", x[1].shape, y[1].shape)

    # 모든 데이터 세트에 대한 모델을 구축하기 위한 입력/출력 크기 가져오기
    input_size = int(x[0].shape[-1])
    output_size = int(max(y[0])) + 1

    # 주어진 구성을 사용하여 모델 빌드
    model = get_model(
        input_size,
        output_size,
        config,
        device,
    ).to(device)
    optimizer = optim.Adam(model.parameters())
    crit = nn.NLLLoss()

    if config.verbose >= 1:
        print(model)
        print(optimizer)
        print(crit)

    # 트레이너 오브젝트 초기화
    trainer = Trainer(model, optimizer, crit)

    # 데이터셋과 설정을 받아와 학습 시작
    trainer.train(
        train_data=(x[0], y[0]),
        valid_data=(x[1], y[1]),
        config=config
    )

    # 최고의 모델을 저장.
    torch.save({
        'model': trainer.model.state_dict(),
        'opt': optimizer.state_dict(),
        'config': config,
    }, config.model_fn)


if __name__ == '__main__':
    config = define_argparser()
    main(config)