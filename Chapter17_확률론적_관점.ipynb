{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPejyZWOhvTPoU9qxKLCurM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgr1118/PyTorch/blob/main/Chapter17_%ED%99%95%EB%A5%A0%EB%A1%A0%EC%A0%81_%EA%B4%80%EC%A0%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17.1 들어가며\n",
        "- 기존에는 신경망 함수가 단순히 특정 샘플 벡터를 출력한다고 생각했었지만 이제는 신경망 함수가 확률 분포를 표현하기 위한 벡터를 출력한다고 볼 수 있다. 그렇다면 좀 더 확률 통계 및 수학적인 관점에서 신경망을 통해 예측하는 과정 설명이 가능할 것입니다. 또한 단순히 딱 정해진 값을 예측하도록 신경망을 학습하는 것이 아니라 불확실성까지 예측하도록 학습시킬 수 있게 될 것이다.\n",
        "\n",
        "- 수식에서 Y and X는 y, x라고 생각하면서 수식을 봐주길 바람"
      ],
      "metadata": {
        "id": "yNEiAiP95v33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17.2 기본 확률 통계\n",
        "- $P(X = x)$\n",
        "- $P(Y = y)$\n",
        "\n",
        "- 이 수식의 의미는 다음과 같다. 변수 X가 x값을 가질 확률과 변수 Y가 y값을 가질 확률을 의미한다. 이때 변수는 연속 값 또는 이산 값일 수 있다. 이 둘의 차이는 이산 확률 변수가 특정 값을 가질 확률(확률 질량)은 구할 수 있지만 연속 확률 변수가 특정 값을 가질 확률(확률 밀도)은 0이라는 것이다.\n",
        "\n",
        "- 이 부분을 다음 예시로 알아보자. 주사위를 던질 때 1 ~ 6까지 특정 숫자가 나올 확률은 1/6이지만, 완벽한 구가 특정 면이 바닥에 닿을 확률은 0이다. 점의 넓이가 0이기 때문이다. 하지만 구의 범위 중에 일부가 바닥에 닿을 확률은 구의 전체 넓이 중 특정 범위의 비율이 될 것이다.\n",
        "\n",
        "- 즉 이산 확률 변수는 다음과 가티 합을 통해 확률을 구할 수 있다.\n",
        "- $\\sum_x P(X = x) = 1, where 0 \\le P(X = x) \\le, \\forall_x \\in \\chi$\n",
        "\n",
        "- 연속 확률 변수의 경우에는 다음과 같이 적분을 통해 구간에 확률을 구할 수 있다.\n",
        "- $\\int p(s)dx = 1, where p(x) \\ge 0, \\forall_x \\in$\n",
        "\n",
        "### 1. 결합 확률\n",
        "- $P(x,y) = P(X = x, Y = y)$같이 두 개 이상의 변수를 사용하는 확률 표현을 결합 확률이라고 합니다. 아래 그림 참조\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/02-joint_prob.png)\n",
        "<center>결합 확률 분포</center>\n",
        "\n",
        "- 만약에 두 변수가 독립적이라면 각 변수의 확률 곱으로도 나타낼 수 있습니다. ML이나 딥러닝 문제에서는 입력과 출력 등을 확률 변수로 나타낼 수 있는데 일반적으로 입력 샘플을 나타내는 변수를 x, 출력 샘플을 나타내는 변수는 y를 사용하여 결합 학률로 나타내는 경우가 많습니다.\n",
        "\n",
        "### 2. 조건부 확률\n",
        "- ML에서 결합 확류보다 더 흔히 사용되는 것이 조건부 확률이다. 앞서 입력 샘플을 x, 출력 샘플을 y라고 표현했다. 입력 샘플 x가 주어졌을 때 출력 샘플 y가 나타날 확률을 $P(Y=y|X=x)$라고 표현한다. 이때 조건부 확률과 결합 확률의 관계는 다음과 같다.\n",
        "\n",
        "- $P(Y|X) = \\frac{P(X,Y)}{P(X)}$\n",
        "- $P(X,Y) = P(Y|X)P(X)$\n",
        "\n",
        "- 이러한 조건부 확률과 결합 확률의 간계를 활용한 것이 베이즈 정리이다. 다음 수식에서 볼 수 있듯이 베이즈 정리를 활용하면 조건부 확률의 앞과 뒤에 나타나는 변수 위치를 반대로 바꿀 수 있다.\n",
        "\n",
        "- $p(h|D) = \\frac{P(D|h)P(h)}{P(D)}$\n",
        "\n",
        "### 3. 변수 ? 값? 분포 ? 함수 ? \n",
        "- 앞 수식들 자세히보면 P() 안에 사용되는 글꼴이 다른 것을 볼 수 있다. 예를 들어 확률 변수를 나타낼 때에는 x로 나타내고, 해당 변수가 어떤 값을 가지는 경우는 $x$로 나타낸다.\n",
        "\n",
        "- $P(X = x) =  P(x)$ (편의상 X는 대문자로 표현)\n",
        "- 따라서 $P(Y|x)$라고 표현한 경우, 이것은 변수 x값에 값 $x$를 넣은 조건이 주어졌을 때의 확률 분포를 의미한다. $P(\\cdot|x)$라고 줄여서 표현하기도 한다. 주의한 점은 $y$가 아닌 y라고 표기되어 있기 때문에 확률 값이 아닌 확률 분포를 의미합니다.만약 확률 값을 나타내고자 한다면 예전처럼 $P(y|x)$라고 표기했을 것이다. 다음 수식도 보면서 생각을 해보자\n",
        "\n",
        "- $f(x) = P(Y = y| X= x)$\n",
        "- 이 형태는 변수 x에 어떤 값이 주어졌을 때 변수 y가 $y$ 값을 가질 확률을 나타낸다. 만약 조건 변수의 값이 바뀐다면 확률 값도 바뀔 것이다. 따라서 이것을 확률의 형태로 바꾼다면 조건부 변수를 함수의 입력, 확률 값을 함수의 출력으로 생각할 수 있습니다.\n",
        "\n",
        "- $P(y|x)$와 같은 형태의 함수 꼴도 생각할 수 있습니다. 이 경우에는 입력의 형태는 같지만 출력의 형태가 확률 값이 아닌 확률 분포가 될 것이다. 함수 출력이 확률 분포라는 것을 파이썬에 적용해보면 실수형(float)값을 반환하는 것이 아니라 분포라는 객체를 반환하는 것으로 생각할 수 있다.\n",
        "\n",
        "### 4. 주변 분포\n",
        "- 결합 확률 분포가 있을 때 하나의 변수를 적분해서 없앨 수 있다. 이것을 주변 확률 분포라고합니다. 수식 참고\n",
        "\n",
        "- $P(x) = \\int P(x, z)dz$\n",
        "- $ \\qquad =  \\int P(x|z)P(z)dz$\n",
        "- $ \\qquad = \\int P(z|x)P(x)dz = P(x) \\int P(z|x)dz$\n",
        "\n",
        "### 5. 샘플링과 기댓값\n",
        "- 확률 개념을 설명할 때 많이 쓰이는 예시로 동전 던지기가 있다. 동전을 던져 어떤 면이 나오는지 확인하는 행위는 확률 분포에서 하나의 샘츨을 추출하는 것과 같다. 만약 앞면이 나오면 +100, 뒷면이 나오면 -100이라고 할 때 동전 던지기의 기대값은 0이다. 이걸 수식으로 작성하면 아래와 같다.\n",
        "\n",
        "- $f(x)=\n",
        "\\begin{cases}\n",
        "+100, & \\mbox{if }\\mbox{1} \\\\\n",
        "-100, & \\mbox{if }\\mbox{0}\n",
        "\\end{cases}$\n",
        "\n",
        "- 동전을 던지는 행위에 대한 확률 분포를 P(x)라고 할 때, 동전을 던져 얻게 될 점수의 기대값은 다음처럼 표현이 가능하다. 이 수식은 기대값이라는 것은 함수에 대한 가중평균임을 알 수 있다.\n",
        "\n",
        "- $\\mathbb{E}_{x~P(x)}[f(x)] = \\sum_{x \\in \\chi}P(x) \\cdot f(x)$\n",
        "- $where \\chi = {0,1}$\n",
        "\n",
        "- 동전 던지기처럼 이산 확률 변수 및 이산 확률 분포이기 때문에 $\\sum$을 통해서 합을 구했지만, 연속 변수의 경우에는 적분을 통해 같은 작업을 진행할 수 있다."
      ],
      "metadata": {
        "id": "qvSiHoHP7lUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17.3 MLE(Maximun Likelihood Estimation - 최대 가능도 방법)\n",
        "- 이 절에서는 딥러닝이 학습되는 원리인 최대 가능도 방법(MLE)에 대하여 알아본다. 다음 그림처럼 과정을 거쳐 데이터를 수집한 후 분포가 정규분포를 따른다고 가정 하에 정규 분포의 평균과 표준 편차를 게산할 수 있다. 평균과 표준편차는 정규분포의 형태를 정의하는 역할을 합니다. 이처럼 확률 분포의 형태를 정의하는 값을 분포의 파라미터라고 부릅니다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-get_height.png)\n",
        "<center>한국 국민의 신장 분포 추정 과정(확률 분포의 형태 정의)</center>\n",
        "\n",
        "- 하지만 평균과 표준편차를 직접 계산할 수 없는 상황에서 다음과 같이 실제 분포에서 추출한 샘플이 존재한다고 가정한다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-samples.png)\n",
        "<center>모집단에서 추출한 샘플</center>\n",
        "\n",
        "- 이 샘플이 정규 분포에서 추출된 것이라고 가정할 때 정규 분포의 파라미터를 알고 싶다. 직접 계산하는 대신 주어진 샘플에 임의의 파라미터를 적용하여 정규 분포를 만들어본다. 정규 분포가 적절하다면 주어진 샘플들이 만들어진 분포 위에서 높은 확률을 지녀야 한다. 따라서 샘플 위의 점선들의 길이가 최대가 되었으면 한다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-approx1.png)\n",
        "<center></center>\n",
        "\n",
        "- 그 후 다시 임의의 파라미터를 적용하여 또 다른 분포를 만들어본다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-approx2.png)\n",
        "<center></center>\n",
        "\n",
        "- 마지막으로 다시 임의의 파라미터를 적용하여 분포를 만들어본다. 앞에서 만든 두 가지보다 이 분포에 점선의 길이가 훨씬 긴 것을 볼 수 있다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-approx3.png)\n",
        "<center></center>\n",
        "\n",
        "- 위 분포가 지금까지 찾은 분포 중 샘플들을 가장 잘 나타낸 것같다. 이때 이 점선 길이의 곱을 가능도라고한다. 결과적으로 우리는 이 점선 길이들의 곱인 가능도를 최대로하는 분포의 파라미터를 찾아내고 싶고 이 방법이 최대 가능도 방법이다.\n",
        "\n",
        "- 수식은 아래와 같다.\n",
        "- $\\mathcal{D} = {x_i}_{i=1}^N$\n",
        "- $Likelihood(\\mu, \\sigma) = \\prod_{i=1}^N p(x_i;\\mu, \\sigma)$\n",
        "\n",
        "- 즉, 가능도는 현재 분포의 파라미터가 수집된 데이터를 얼마나 잘 설명하는지 나타내는 점수라고 볼 수 이다. 가능도 함수는 분포의 파라미터의 변화에 따라 변화하는 가능도를 나타낸 것이다.\n",
        "\n",
        "- 간단한 예시를 통하여 MLE를 이해해보자. 주사위 던지기 결과에 대한 데이터 셋이있다. $\\mathcal{D} = {5,6,4,6,5,2,6,1,5,3,1,6,4,2,5,6,2,1,4,5}$ 충분히 많은 샘플이 있다면 예측된 분포의 신뢰도가 높을 것이고, 이를 바탕으로 판단하면 데이터의 조작이 있었는지 알 수 있다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-dice_stat.png)\n",
        "<center>주사위의 분포 예측</center>\n",
        "\n",
        "- 하지만 이러한 방법이 불가할 때 MLE를 통해서 주사위의 분포를 예측할 수도 있다. 다음과 같이 임의의 파라미터 $\\theta_{1}$, $\\theta_{2}$를 통해 두 개의 분포를 만들었다고 가정해본다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-dice_mle1.png)\n",
        "<center>MLE를 통한 주사위 분포 예측</center>\n",
        "\n",
        "- 각 분포에 대해서 가능도를 구해본다\n",
        "\n",
        "- \\begin{aligned}\n",
        "\\text{Likelihood}(\\theta_1)&=\\prod_{i=1}^{N=20}{\n",
        "    P_{\\theta_1}(\\text{x}=x_i)\n",
        "} \\\\\n",
        "&=0.1^3\\times0.1^3\\times0.1^1\\times0.1^3\\times0.1^5\\times0.5^5 \\\\\n",
        "&=3.125e-17 \\\\\n",
        "\\\\\n",
        "\\text{Likelihood}(\\theta_2)&=\\prod_{i=1}^{N=20}{\n",
        "    P_{\\theta_2}(\\text{x}=x_i)\n",
        "} \\\\\n",
        "&=0.1^5\\times0.1^3\\times0.1^1\\times0.1^3\\times0.1^5\\times0.1^5 \\\\\n",
        "&=1.25e-18\n",
        "\\end{aligned}\n",
        "\n",
        "- 파라미터 $\\theta_{1}$의 분포가 더 높은 가능도를 갖고 있음을 알 수 있다. 곧이어 새로운 $\\theta_{3}$를 생성한다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-dice_mle2.png)\n",
        "<center>새로운 파라미터인 $\\theta_{3}$의 분포 생성</center>\n",
        "\n",
        "- \\begin{aligned}\n",
        "\\text{Likelihood}(\\theta_1)&=3.125e-17 \\\\\n",
        "\\\\\n",
        "\\text{Likelihood}(\\theta_3)&=\\prod_{i=1}^{N=20}{\n",
        "    P_{\\theta_3}(\\text{x}=x_i)\n",
        "} \\\\\n",
        "&=0.15^5\\times0.15^3\\times0.05^1\\times0.15^3\\times0.25^5\\times0.25^5 \\\\\n",
        "&=1.833e-15\n",
        "\\end{aligned}\n",
        "\n",
        "- 이번에는 $\\theta_{3}$가 훨씬 높은 가능도를 가지는 것을 볼 수 있다. 이같은 과정을 반복하다보면 점점 실제 주사위의 분포와 비슷한 분포를 얻을 수 있을 것이다.\n",
        "\n",
        "### 1. 로그 가능도\n",
        "- 앞의 예제에서 보듯이 가능도는 확률의 곱이다. 따라서 샘플의 숫자가 많아진다면 가능도의 크기는 굉장히 작아질 가능성이 높다. 그렇다면 이것을 계산할 때 언더플로에 빠질 가능성이 높다. 이때 로그를 도입하여 확률의 곱셈을 덧셈으로 바꿀 수 있다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\prod_{i=1}^N{\n",
        "    P_\\theta(\\text{x}=x_i)\n",
        "}\n",
        "\\Rightarrow\n",
        "\\sum_{i=1}^N{\n",
        "    \\log{P_\\theta(\\text{x}=x_i)}\n",
        "}\n",
        "\\end{gathered}\n",
        "\n",
        "### 2. 경사상승법을 통한 MLE\n",
        "- MLE를 통하여 파라미터의 분포를 찾을 때 운이없다면 오랜 시간이 걸릴 것이다. 이때 딥러닝에서 사용하던 경사하강법과 경사상승법을 활용하여 MLE을 더 쉽게 수행한다. 경사하강법이 손실 함수를 최소화하는 파라미터를 찾았던 것처럼 경사상승법을 통해 가능도 함수를 최대화하는 파라미터를 찾아보도록 한다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\theta\\leftarrow\\theta+\\alpha\\cdot\\frac{\\partial{\\mathcal{L}(\\theta)}}{\\partial{\\theta}}\n",
        "\\end{gathered}\n",
        "\n",
        "- 예시로 동전을 100번 던질 때 앞 면이 27번 나오는 동전이 있다고 할 때, 이 동전의 파라미터를 MLE를 통해 추정하면 다음과 같이 할 수 있다. 먼저 동전을 여러 번 던지는 작업은 이항 분포를 따른다고 가정한다. 그럼 이 분포의 확률 질량 함수는 다음과 같다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "f(k,n,\\theta)=\\frac{n!}{k!(n-k)!}\\times\\theta^k\\times(1-\\theta)^{n-k}\n",
        "\\end{gathered}\n",
        "\n",
        "- 여기서 n = 100, k = 27을 적용하여 가능도 함수를 그림으로 그려보면 다음과 같다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/03-binomial_mle.png)\n",
        "<center></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "IjP5M4rXYQTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17.4 신경망과 MLE\n",
        "- 가능도는 대이터 샘플을 주어진 분포의 파라미터로 얼마나 잘 설명하는지 수치화한 것이라고 설명했다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\text{LogLikelihood}(\\theta)=\\sum_{i=1}^N{\n",
        "    \\log{P_\\theta(y_i|x_i)}\n",
        "}\n",
        "\\end{gathered}\n",
        "\n",
        "- 이 수식에서 $log{P_\\theta(y_i|x_i)}$는 $\\theta$라는 파라미터를 갖는 분포에 $x_i$가 주어졌을 때의 $y_i$의 확률을 의미하는 하나의 샘플 쌍에 대한 가능도가 된다. 또한 분포의 파라미터 표현과 관련해서 다음 수식은 모두 같은 표현이다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "P_\\theta(x_i)=P(x_i;\\theta)=P(x_i,\\theta) \\\\\n",
        "P_\\theta(y_i|x_i)=P(y_i|x_i;\\theta)=P(y_i|x_i,\\theta)\n",
        "\\end{gathered}\n",
        "\n",
        "### 1. 잠깐 복습\n",
        "- 책의 초반부에서 인공지능 모델은 하나의 함수이고 우리 머릿속에서 존재하는 가상의 함수를 근사계산하는 것이 목표라고 하였다. 그 과정은 다음 수식을 따른다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\mathcal{D}=\\{(x_i,y_i)\\}_{i=1}^N \\\\\n",
        "\\\\\n",
        "\\mathcal{L}(\\theta)=\\sum_{i=1}^N{\n",
        "    \\|y_i-\\hat{y}_i\\|\n",
        "}, \\\\\n",
        "\\text{where }\\hat{y}_i=f_\\theta(x_i). \\\\\n",
        "\\\\\n",
        "\\hat{\\theta} = \\underset{\\theta\\in\\Theta}{\\argmin}{\n",
        "    \\mathcal{L}(\\theta)\n",
        "} \\\\\n",
        "\\\\\n",
        "\\theta\\leftarrow\\theta-\\eta\\cdot\\frac{\\partial{\\mathcal{L}(\\theta)}}{\\partial{\\theta}}\n",
        "\\end{gathered}\n",
        "\n",
        "- 만약 회귀가 아닌 분류 문제일 경우, 손실 함수 $\\mathcal{L}$은 다음과 같이 바뀐다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\mathcal{L}(\\theta)=-\\sum_{i=1}^N{\n",
        "    y_i^\\intercal\\cdot\\log{\\hat{y}_i}, \n",
        "} \\\\\n",
        "\\text{where }\\hat{y}_i=f_\\theta(x_i).\n",
        "\\end{gathered}\n",
        "\n",
        "- 이때 분류 모델의 출력 벡터 $\\hat{y}_i$는 소프트맥스의 결과 값이다,\n",
        "\n",
        "### 2. 신경망의 출력과 확률 분포\n",
        "- 신경망과 MLE는 어떤 관계인가? 라는 질문을 답하려면 DNN 모델 또한 확률 분포 함수라고 가정한다면 답할 수 있다. 즉, DNN의 가중치 파라미터가 분포를 나타내는 파라미터이며 신경망의 출력의 출력이 가중치 파라미터의 변화에 따른 확률 분포라고 볼 수 있다.\n",
        "\n",
        "- 다음과 같이 DNN이 주어질 때 3개 계층의 각 가중치 파라미터들은 신경망의 동작을 정의하게 되고 결과적으로 분포의 파라미터로 취급받을 수 있다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/04-dnn.png)\n",
        "<center>DNN의 가중치 파라미터</center>\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\theta=\\{W_1,b_1,W_2,b_2,\\cdots,W_\\ell,b_\\ell\\}\n",
        "\\end{gathered}\n",
        "\n",
        "- 앞서 언급한 MLE 방식과 마찬가지로 최대 가능도를 만드는 파라미터를 경사상승법을 구할 수 있지만 딥러닝 프레임워크는 대부분은 경사하강법만 지원한다. 따라서 우리는 NLL(negative log-likelihood)을 도입하여 최대화 문제를 최소화 문제로 바꾸고 경사하강법을 통해 MLE를 구현할 수 있다.\n",
        "\n",
        "- $\\mathcal{D} = \\begin{Bmatrix} {(x_i, y_i)}\\end{Bmatrix}_{i=1}^N$\n",
        "- $NLL(\\theta) = - \\sum_{i=1}^N logP(y_i|x_i;\\theta)$\n",
        "- $\\hat{\\theta} =  \\underset{\\theta \\in \\mathit{theta}}{\\overset{}{_{}^{}argmin_{}^{}}} \\mathcal{L}(\\theta)$\n",
        "- $\\theta < \\theta - \\eta \\cdot \\frac{\\partial\\mathcal{L}(\\theta)}{\\partial\\theta}$\n",
        "\n",
        "- 이전 방식에서는 $\\hat{y_i} = f_{\\theta}(x_i)$라고 손실 함수를 정의했는데 MLE방식을 활용한 NLL 목적 함수에서는 신경망이 어떻게 활용되고 있을까?\n",
        "\n"
      ],
      "metadata": {
        "id": "oJDR9yZOw7wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17.5 수식:MLE\n",
        "- 이 절에서는 저번 절에서 던진 질문에 답을 할 것이다. 다음과 같이 DNN이 있다.\n",
        "\n",
        "![](https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/2-02/05-dnn_with_softmax.png)\n",
        "<center>DNN의 구성</center>\n",
        "\n",
        "- 소프트맥스 계층으로부터 출력된 벡터 $\\hat{y_i}$의 각 차원들은 미리 지정된 클래스에 대한 확률 값을 담고 있을 것이다. 다음과 같이 수집된 데이터 쌍이 N개가 있다고 할 때 아래와 같이 나타날 것이다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\mathcal{D}=\\{(x_i,y_i)\\}_{i=1}^N\n",
        "\\end{gathered}\n",
        "\n",
        "- 우리가 찾고자하는 파라미터는 NLL 함수를 최소화하는 파라미터가 될 것이다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\hat{\\theta} = \\underset{\\theta \\in \\Theta}{argmin}{\n",
        "    -\\sum_{i=1}^N{\n",
        "        \\log{P(y_i|x_i;\\theta)}\n",
        "    }\n",
        "}\n",
        "\\end{gathered}\n",
        "\n",
        "- 여기서 DNN의 출력 벡터 $\\hat{y_i}$는 소프트맥스 함수의 출력값이므로 벡터의 각 차원은 클래스에 대한 확률 값을 담고있는데 이것은 이산 확률 분포로 생각할 수 있다. 그럼 로그 가능도 $log(y_i:x_i;\\theta)$는 다음과 같이 구할 수 있다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "\\log{P(y_i|x_i;\\theta)}=\\hat{y}_i^\\intercal\\cdot\\log{y_i}\n",
        "\\end{gathered}\n",
        "\n",
        "- 이것을 실제 벡터 수준에서 예제를 통해보면 다음과 같이 구할 수 있다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "y_i=\\begin{bmatrix}\n",
        "    0 \\\\\n",
        "    0 \\\\\n",
        "    1 \\\\\n",
        "    0\n",
        "\\end{bmatrix}\n",
        "\\text{ and }\n",
        "P_\\theta(\\cdot|x_i)=\\hat{y}_i=\\begin{bmatrix}\n",
        "    .2 \\\\\n",
        "    .1 \\\\\n",
        "    .65 \\\\\n",
        "    .05\n",
        "\\end{bmatrix}.\n",
        "\\end{gathered}\n",
        "\n",
        "- 앞에서의 수식에 따라 내적을 취하면 로그 가능도를 계산할 수 있다.\n",
        "\n",
        "- \\begin{aligned}\n",
        "y_i^\\intercal\\cdot\\log{\\hat{y}_i}&=[0,0,1,0]\\times\\log{\\begin{bmatrix}\n",
        "    .2 \\\\\n",
        "    .1 \\\\\n",
        "    .65 \\\\\n",
        "    .05\n",
        "\\end{bmatrix}} \\\\\n",
        "&=0\\times\\log{0.2}+0\\times\\log{0.1}+1\\times\\log{0.65}+0\\times\\log{0.05} \\\\\n",
        "&=\\log{0.65} \\\\\n",
        "&=\\log{P(\\text{y}=2|x_i;\\theta)}\n",
        "\\end{aligned}\n",
        "\n",
        "### 1. 교차 엔트로피와 NLL\n",
        "- 분류 문제에 대해서 배울 때 교차 엔트로피에 대해서 설명했다. \n",
        "- \\begin{gathered}\n",
        "\\text{CE}(y_{1:N},\\hat{y}_{1:N})=-\\frac{1}{N}\\sum_{i=1}^N{\n",
        "    y_i^\\intercal\\cdot\\log{\\hat{y}_i}\n",
        "}\n",
        "\\end{gathered}\n",
        "\n",
        "- 교차 엔트로피를 통해 DNN을 학습하기 위해 파라미터 $\\theta$에 대한 손실 함수로 구성하면 다음과 같을 것이다.\n",
        "- \\begin{gathered}\n",
        "\\mathcal{L}_\\text{CE}(\\theta)=-\\frac{1}{N}\\sum_{i=1}^N{\n",
        "    y_i^\\intercal\\cdot\\log{f_\\theta(x_i)}\n",
        "}\n",
        "\\end{gathered}\n",
        "\n",
        "- 위에서 알아본 NLL 손실 함수와 유사한 형태가 나온다. 이처럼 교차 엔트로피 손실 함수를 통해 DNN을 학습하는 것은 NLL 손실 함수 및 MSE를 통해 심승신경망을 학습하는 것과 같다.\n"
      ],
      "metadata": {
        "id": "5uM4NbTq32VR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17.6 MSE 손실 함수와 MLE\n",
        "- 분류 문제에서는 교차 엔트로피 손실 함수를 사용했고, 회귀 문제에서는 MSE 손실 함수를 사용했다. 이런 점때문에 MLE를 비롯한 로드 가능도는 분류 문제에만 해당한다고 생각이 들 수 있다. 하지만 MSE 손실 함수의 경우에도 여전히 같은 범위의 원리에서 동작하고 있음을 보여줄 수 있다.\n",
        "\n",
        "- 다음 수식은 가우시안 분포의 확률 밀도 함수이다. 여기에 로그에 음수를 취해보자\n",
        "\n",
        "- \\begin{gathered}\n",
        "p(x;\\mu,\\sigma)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\big(\\frac{x-\\mu}{\\sigma}\\big)^2} \\\\\n",
        "\\\\\n",
        "\\log{p(x;\\mu,\\sigma)}=-\\log{\\sigma\\sqrt{2\\pi}}-\\frac{1}{2}\\big(\\frac{x-\\mu}{\\sigma}\\big)^2 \\\\\n",
        "\\\\\n",
        "-\\log{p(x;\\mu,\\sigma)}=\\log{\\sigma\\sqrt{2\\pi}}+\\frac{1}{2}\\big(\\frac{x-\\mu}{\\sigma}\\big)^2\n",
        "\\end{gathered}\n",
        "\n",
        "- 이때 DNN 모델의 출력이 가우시안 분포라고 가정하고, 좀 더 정확하게는 가우시안 분포의 평균과 표준편차를 반환한다고 생각할 수 있다. 앞 절 분류 문제의 DNN이 소프트맥스 함수를 통해 이산 확률 분포를 반환한 것과 마찬가지입니다. 확률 분포의 파라미터를 가지고 있으면 확률 분포를 그대로 만들어 낼 수 있기 때문이다. 따라서 각각의 파라미터가 $\\boldsymbol{\\phi}$, $\\boldsymbol{\\psi}$인 두 개의 DNN이 있고, 각 신경망은 평균과 표준편차를 반환하여 가우시안 분포를 반환하고 있다고 볼 수 있다. 그럼 음의 로그 가능도는 다음과 같이 계산된다.\n",
        "\n",
        "- \\begin{gathered}\n",
        "-\\log{p(y_i|x_i;\\phi,\\psi)}=\\log{\\sigma_\\psi(x_i)\\sqrt{2\\pi}}+\\frac{1}{2}\\big(\\frac{y_i-\\mu_\\phi(x_i)}{\\sigma_\\psi(x_i)}\\big)^2, \\\\\n",
        "\\text{where }\\theta=\\{\\phi,\\psi\\}.\n",
        "\\end{gathered}\n",
        "\n",
        "- 그러면 NLL을 최소화하는 방향으로 파라미터를 업데이트해야 하므로 경사하강법을 수행하기위해 NLL 함수를 가중치 파라미터로 미분해야한다. 그럼 파라미터 $\\boldsymbol{\\phi}$로 미분했을 때의 수식 전개는 다음과 같다.\n",
        "\n",
        "- \\begin{aligned}\n",
        "-\\nabla_\\phi\\log{p(y_i|x_i;\\phi,\\psi)}&=\\nabla_\\phi\\log{\\sigma_\\psi(x_i)\\sqrt{2\\pi}}+\\nabla_\\phi\\frac{1}{2}\\big(\\frac{y_i-\\mu_\\phi(x_i)}{\\sigma_\\psi(x_i)}\\big)^2 \\\\\n",
        "&=\\frac{1}{2\\cdot\\sigma_\\psi(x_i)^2}\\nabla_\\phi\\big(y_i-\\mu_\\phi(x_i)\\big)^2 \\\\\n",
        "&=\\alpha\\cdot\\nabla_\\phi\\big(y_i-\\mu_\\phi(x_i)\\big)^2\\text{, where }\\alpha=\\frac{1}{2\\cdot\\sigma_\\psi(x_i)^2}.\n",
        "\\end{aligned}\n",
        "\n",
        "- 결과적으로 상수를 제외하고 나면 MSE 손실 함수를 미분하는 것과 같은 형태임을 알 수 있습니다. 즉, 회귀 문제에서 신경망이 가우시안 분포의 평균을 출력하고 있다면 하나면 여전히 분류 문제와 같은 원리 내에서 동작하고 있음을 알 수 있습니다.\n",
        "\n",
        "## 요약\n",
        "\n",
        "1. 가능도\n",
        " - 가능도란 데이터 샘플들을 주어진 분포의 파라미터로 얼마나 잘 설명하는지 수치화한 것\n",
        "\n",
        "2. MLE\n",
        " - DNN을 확률 분포 함수로 해석할 수 있으며 이에 따라 MLE를 통해 모델을 학습할 수 있다.\n",
        " - 음의 가능도 손실 함수를 통해 MLE를 수행\n",
        " - NLL 손실 함수는 교차 엔트로피 손실 함수와 수식이 거의 같다. (수식은 위 설명을 참고)"
      ],
      "metadata": {
        "id": "FDuzIOZE9Z2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lJDsXaFbZGGD"
      }
    }
  ]
}